import cv2
import subprocess as sp
import numpy as np
import torch
from pathlib import Path
from yolov5 import YOLOv5
import time
from concurrent.futures import ThreadPoolExecutor
import threading
import os

frame_counter = 0
start_time = time.time()

# é€‰æ‹©CPUè¿˜æ˜¯GPU
def select_device(device='', batch_size=0, newline=True):
    s = f'YOLOv5 ðŸš€ {torch.__version__} '
    device = str(device).strip().lower().replace('cuda:', '').replace('none', '')
    cpu = device == 'cpu'
    if cpu:
        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
    elif device:
        os.environ['CUDA_VISIBLE_DEVICES'] = device
        assert torch.cuda.is_available() and torch.cuda.device_count() >= len(device.replace(',', '')), \
            f"Invalid CUDA '--device {device}' requested, use '--device cpu' or pass valid CUDA device(s)"

    if not cpu and torch.cuda.is_available():
        devices = device.split(',') if device else '0'
        n = len(devices)
        if n > 1 and batch_size > 0:
            assert batch_size % n == 0, f'batch-size {batch_size} not multiple of GPU count {n}'
        space = ' ' * (len(s) + 1)
        for i, d in enumerate(devices):
            p = torch.cuda.get_device_properties(i)
            s += f"{'' if i == 0 else space}CUDA:{d} ({p.name}, {p.total_memory / (1 << 20):.0f}MiB)\n"
        arg = 'cuda:0'
    else:
        s += 'CPU\n'
        arg = 'cpu'

    if not newline:
        s = s.rstrip()
    print(s)
    return torch.device(arg)

# æ­¤ä¸ºå¢žåŠ äº†äººä¸Žè½¦çš„æ ‡ç­¾ï¼Œåœ¨ç”»æ¡†æ—¶åªæœ‰äººå’Œè½¦
def draw_bboxes(img, results):
    for *box, conf, cls in results.xyxy[0]:
        if int(cls) in [0, 1]:  # åªç»˜åˆ¶äººå’Œè½¦ä¸¤ä¸ªç±»åˆ«çš„æ£€æµ‹ç»“æžœ
            label = f"{results.names[int(cls)]} {conf:.2f}"
            x1, y1, x2, y2 = map(int, box)
            img = cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)
            img = cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
    return img

# å°†å¤„ç†æ¯ä¸ªè§†é¢‘å¸§çš„ä»»åŠ¡åŒ…è£…ä¸ºä¸€ä¸ªå‡½æ•°
def process_frame(frame):
    global model
    results = model.predict(frame)
    return draw_bboxes(frame, results)


# è¾“å…¥è§†é¢‘æ–‡ä»¶å
input_video = 'C:/1602646269313.mp4'

# ä½¿ç”¨ffprobeèŽ·å–è§†é¢‘ä¿¡æ¯
ffprobe_cmd = ['ffprobe', '-v', 'error', '-select_streams', 'v:0',
               '-show_entries', 'stream=width,height,r_frame_rate',
               '-of', 'csv=p=0', input_video]
info = sp.check_output(ffprobe_cmd).decode('utf-8').split(',')
width, height = map(int, info[:2])

# è®¾ç½®ç¼©æ”¾åŽçš„å®½åº¦å’Œé«˜åº¦
# new_width, new_height = width // 2, height // 2

fps = round(eval(info[2]))

# è®¾ç½®FFmpegå‘½ä»¤
command = ['ffmpeg',
           '-i', input_video,
           # '-vf', 'scale={}:{}'.format(new_width, new_height), # è®¾ç½®ç¼©æ”¾åŽçš„å®½åº¦å’Œé«˜åº¦
           '-vf', 'scale={}:{}'.format(width, height),
           '-c:v', 'rawvideo',
           '-pix_fmt', 'bgr24',
           '-threads', '12',
           '-f', 'rawvideo',
           'pipe:']

device = select_device(0)

# åˆå§‹åŒ–YOLOv5æ¨¡åž‹
model_path = 'F:/12-Python/yolov5/pre_modelsfile_yolov5/yolov5s.pt'
model = YOLOv5(model_path, device=device)

# å¯åŠ¨FFmpegå­è¿›ç¨‹
pipe = sp.Popen(command, stdout=sp.PIPE, bufsize=10**8)

# åˆ›å»ºcv2.VideoCaptureå¯¹è±¡
cap = cv2.VideoCapture(input_video)

# è®¾ç½®ç¼“å†²åŒºå¤§å°
buffer_size = 10
cap.set(cv2.CAP_PROP_BUFFERSIZE, buffer_size)

# åˆ›å»ºçº¿ç¨‹æ± 
executor = ThreadPoolExecutor(max_workers=12)

skip_frames = 1  # è·³è¿‡çš„å¸§æ•°
frame_counter = 0

while True:
    ret, frame = cap.read()


    if not ret:
        break

    if not ret or frame_counter % skip_frames != 0:
        frame_counter += 1
        continue


    # è£åˆ‡ç”»é¢ä¸ºåŽŸé«˜åº¦çš„60%
    height_crop = int(height * 0.8)
    crop_top = int(height * 0.1)
    frame = frame[crop_top:crop_top + height_crop, :, :]

    # è®¡æ—¶
    frame_counter += 1
    if frame_counter % 10 == 0:  # æ¯10å¸§è¾“å‡ºä¸€æ¬¡ä¿¡æ¯
        elapsed_time = time.time() - start_time
        print(f"Processed frames: {frame_counter}, elapsed time: {elapsed_time:.2f}s")

    # ä½¿ç”¨çº¿ç¨‹æ± å¤„ç†å¸§
    future = executor.submit(process_frame, frame)
    processed_frame = future.result()

    # é€šè¿‡threadingæ¨¡å—æ¥æŸ¥çœ‹ç¨‹åºè¿è¡Œæ—¶çš„å®žé™…çº¿ç¨‹æ•°é‡
    active_threads = threading.active_count()
    print(f"Active threads: {active_threads}")

    # # ä½¿ç”¨YOLOv5æ¨¡åž‹è¿›è¡Œç›®æ ‡æ£€æµ‹
    # results = model.predict(frame)
    #
    # # åœ¨å¸§ä¸Šç»˜åˆ¶æ£€æµ‹æ¡†
    # frame = draw_bboxes(frame, results)

    # æ˜¾ç¤ºè§£ç åŽçš„å¸§
    cv2.imshow('Video', frame)
    if cv2.waitKey(int(1000/ fps)) & 0xFF == ord('q'):
        break

    pipe.stdout.flush()

cv2.destroyAllWindows()

# ç¡®ä¿å­è¿›ç¨‹å·²ç»ç»“æŸå¹¶é‡Šæ”¾èµ„æº
pipe.communicate()