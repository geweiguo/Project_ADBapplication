# opencv å’Œ pytorchéƒ½ä½¿ç”¨CPUè¿›è¡Œè§†é¢‘å¸§å¤„ç†å’Œæ¨ç†è®¡ç®—
# æ­¤ä»£ç å­˜åœ¨CPUçº¿ç¨‹ä½¿ç”¨ä¸å……åˆ†ç°è±¡


import cv2
import subprocess as sp
import numpy as np
import torch
from pathlib import Path
from yolov5 import YOLOv5
import time
from concurrent.futures import ThreadPoolExecutor
import threading
import os


frame_counter = 0
start_time = time.time()

# é€‰æ‹©CPUè¿˜æ˜¯GPU
def select_device(device='', batch_size=0, newline=True):
    s = f'YOLOv5 ğŸš€ {torch.__version__} '
    device = str(device).strip().lower().replace('cuda:', '').replace('none', '')
    cpu = device == 'cpu'
    if cpu:
        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
    elif device:
        os.environ['CUDA_VISIBLE_DEVICES'] = device
        assert torch.cuda.is_available() and torch.cuda.device_count() >= len(device.replace(',', '')), \
            f"Invalid CUDA '--device {device}' requested, use '--device cpu' or pass valid CUDA device(s)"

    if not cpu and torch.cuda.is_available():
        devices = device.split(',') if device else '0'
        n = len(devices)
        if n > 1 and batch_size > 0:
            assert batch_size % n == 0, f'batch-size {batch_size} not multiple of GPU count {n}'
        space = ' ' * (len(s) + 1)
        for i, d in enumerate(devices):
            p = torch.cuda.get_device_properties(i)
            s += f"{'' if i == 0 else space}CUDA:{d} ({p.name}, {p.total_memory / (1 << 20):.0f}MiB)\n"
        arg = 'cuda:0'
    else:
        s += 'CPU\n'
        arg = 'cpu'

    if not newline:
        s = s.rstrip()
    print(s)
    return torch.device(arg)

# æ­¤ä¸ºå¢åŠ äº†äººä¸è½¦çš„æ ‡ç­¾ï¼Œåœ¨ç”»æ¡†æ—¶åªæœ‰äººå’Œè½¦
def draw_bboxes(img, results):
    for *box, conf, cls in results.xyxy[0]:
        if int(cls) in [0, 1]:  # åªç»˜åˆ¶äººå’Œè½¦ä¸¤ä¸ªç±»åˆ«çš„æ£€æµ‹ç»“æœ
            label = f"{results.names[int(cls)]} {conf:.2f}"
            x1, y1, x2, y2 = map(int, box)
            img = cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)
            img = cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
    return img

def process_frame(frame, model):
    results = model.predict(frame)
    frame = draw_bboxes(frame, results)
    return frame

# è¾“å…¥è§†é¢‘æ–‡ä»¶å
input_video = 'G:/02-è§†é¢‘/03-è‘›ç§’å²‘/2021/1602646269313.mp4'

# ä½¿ç”¨ffprobeè·å–è§†é¢‘ä¿¡æ¯
ffprobe_cmd = ['ffprobe', '-v', 'error', '-select_streams', 'v:0',
               '-show_entries', 'stream=width,height,r_frame_rate',
               '-of', 'csv=p=0', input_video]
info = sp.check_output(ffprobe_cmd).decode('utf-8').split(',')
width, height = map(int, info[:2])

# è®¾ç½®ç¼©æ”¾åçš„å®½åº¦å’Œé«˜åº¦
# new_width, new_height = width // 2, height // 2

fps = round(eval(info[2]))

# è®¾ç½®FFmpegå‘½ä»¤
command = ['ffmpeg',
           '-i', input_video,
           # '-vf', 'scale={}:{}'.format(new_width, new_height), # è®¾ç½®ç¼©æ”¾åçš„å®½åº¦å’Œé«˜åº¦
           '-vf', 'scale={}:{}'.format(width, height),
           '-c:v', 'rawvideo',
           '-pix_fmt', 'bgr24',
           '-threads', '12',
           '-f', 'rawvideo',
           'pipe:']

device = select_device('cpu')  # ä½¿ç”¨CPU

# åˆå§‹åŒ–YOLOv5æ¨¡å‹
model_path = 'F:/12-Python/yolov5/pre_modelsfile_yolov5/yolov5s.pt'
model = YOLOv5(model_path, device=device)

# å¯åŠ¨FFmpegå­è¿›ç¨‹
pipe = sp.Popen(command, stdout=sp.PIPE, bufsize=10**8)

# åˆ›å»ºcv2.VideoCaptureå¯¹è±¡
cap = cv2.VideoCapture(input_video)

# è®¾ç½®ç¼“å†²åŒºå¤§å°
buffer_size = 2
cap.set(cv2.CAP_PROP_BUFFERSIZE, buffer_size)

# åˆ›å»ºçº¿ç¨‹æ± 
executor = ThreadPoolExecutor(max_workers=8)

frames = []
futures = []

skip_frames = 1  # è·³è¿‡çš„å¸§æ•°
frame_counter = 0

while True:
    ret, frame = cap.read()

    if not ret:
        break


    # è£åˆ‡ç”»é¢ä¸ºåŸé«˜åº¦çš„60%
    height_crop = int(height * 0.8)
    crop_top = int(height * 0.1)
    frame = frame[crop_top:crop_top + height_crop, :, :]

    # è®¡æ—¶
    frame_counter += 1
    if frame_counter % 10 == 0:  # æ¯10å¸§è¾“å‡ºä¸€æ¬¡ä¿¡æ¯
        elapsed_time = time.time() - start_time
        print(f"Processed frames: {frame_counter}, elapsed time: {elapsed_time:.2f}s")

    # ä½¿ç”¨çº¿ç¨‹æ± å¤„ç†å¸§
    future = executor.submit(process_frame, frame, model)
    futures.append(future)

    # é€šè¿‡threadingæ¨¡å—æ¥æŸ¥çœ‹ç¨‹åºè¿è¡Œæ—¶çš„å®é™…çº¿ç¨‹æ•°é‡
    active_threads = threading.active_count()
    print(f"Active threads: {active_threads}")

    # # ä½¿ç”¨YOLOv5æ¨¡å‹è¿›è¡Œç›®æ ‡æ£€æµ‹
    # results = model.predict(frame)
    #
    # # åœ¨å¸§ä¸Šç»˜åˆ¶æ£€æµ‹æ¡†
    # frame = draw_bboxes(frame, results)

    # è·å–å¤„ç†åçš„å¸§å¹¶æ˜¾ç¤º
    if len(futures) > 8:  # åœ¨æ­¤å¤„è°ƒæ•´ç¼“å†²åŒºå¤§å°ä»¥ä¿æŒå¸§é¡ºåº
        processed_frame = futures.pop(0).result()
        cv2.imshow('Video', processed_frame)
        if cv2.waitKey(int(800 / fps)) & 0xFF == ord('q'):
            break

    pipe.stdout.flush()

cv2.destroyAllWindows()
pipe.terminate()
