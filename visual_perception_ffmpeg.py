"""
1.1 æœ¬ç¨‹åºå®ç°çš„åŠŸèƒ½ï¼šä½¿ç”¨YOLOv5å¯¹è¾“å…¥çš„è§†é¢‘æ–‡ä»¶è¿›è¡Œç›®æ ‡æ£€æµ‹ï¼Œå¹¶å®æ—¶æ˜¾ç¤ºæ£€æµ‹ç»“æœ
1.2 å›¾åƒå¸§å¤„ç†å’Œè§†è§‰è¯†åˆ«æ¨ç†åˆ†åˆ«é‡‡ç”¨çš„æ˜¯ä»€ä¹ˆè®¡ç®—æ–¹æ¡ˆï¼šå›¾åƒå¸§å¤„ç†ä½¿ç”¨CPUï¼Œè§†è§‰è¯†åˆ«æ¨ç†ä½¿ç”¨GPU
1.3 ç‰ˆæœ¬ï¼š1.0ï¼Œæ—¥æœŸï¼š2023-04-11


ä»£ç å·²æŒ‰ç…§æ‚¨çš„è¦æ±‚è¿›è¡Œäº†æ•´ç†å’Œæ·»åŠ å¤‡æ³¨ã€‚æ¯ä¸ªå‡½æ•°çš„åŠŸèƒ½å¦‚ä¸‹ï¼š

1. åŠ è½½æ¨¡å‹ï¼š`load_model` - åŠ è½½é¢„è®­ç»ƒçš„YOLOv5æ¨¡å‹ã€‚
2. è®¾ç½®GPUï¼š`select_device` - æ ¹æ®ç”¨æˆ·è¾“å…¥é€‰æ‹©ä½¿ç”¨çš„è®¾å¤‡ï¼ˆCPUæˆ–GPUï¼‰ã€‚
3. è·å–è§†é¢‘æºï¼š`get_video_info` - ä½¿ç”¨`ffprobe`è·å–è¾“å…¥è§†é¢‘çš„ç›¸å…³ä¿¡æ¯ï¼ˆå®½åº¦ã€é«˜åº¦ã€å¸§ç‡ï¼‰ã€‚
4. é¢„å¤„ç†è§†é¢‘å¸§ï¼š`preprocess_frame` - å¯¹è¾“å…¥çš„è§†é¢‘å¸§è¿›è¡Œè£å‰ªã€‚
5. è¿è¡Œç›®æ ‡æ£€æµ‹ï¼š`process_frame` - ä½¿ç”¨YOLOv5æ¨¡å‹å¯¹è¾“å…¥çš„è§†é¢‘å¸§è¿›è¡Œç›®æ ‡æ£€æµ‹ã€‚
6. åå¤„ç†ï¼š`draw_bboxes` - åœ¨è¾“å…¥çš„å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹åˆ°çš„è¾¹ç•Œæ¡†ã€‚
7. æ˜¾ç¤ºç»“æœï¼šå·²é›†æˆåœ¨ä¸»ç¨‹åºæµç¨‹ä¸­ï¼Œä½¿ç”¨`cv2.imshow`å®æ—¶æ˜¾ç¤ºå¤„ç†åçš„è§†é¢‘å¸§ã€‚
8. é‡Šæ”¾èµ„æºï¼šå·²é›†æˆåœ¨ä¸»ç¨‹åºæµç¨‹ä¸­ï¼Œä½¿ç”¨`cv2.destroyAllWindows`å’Œ`pipe.communicate`é‡Šæ”¾èµ„æºã€‚

"""

import cv2
import subprocess as sp
import torch
from yolov5 import YOLOv5
import time
from concurrent.futures import ThreadPoolExecutor
import threading
import os

#1. åŠ è½½æ¨¡å‹
def load_model(model_path, device):
    """
    åŠ è½½é¢„è®­ç»ƒçš„YOLOv5æ¨¡å‹ã€‚
    :param model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
    :param device: è®¡ç®—è®¾å¤‡ï¼ˆCPUæˆ–GPUï¼‰
    :return: åŠ è½½çš„æ¨¡å‹å®ä¾‹
    """
    return YOLOv5(model_path, device=device)


#2. è®¾ç½®GPU
def select_device(device='', batch_size=0, newline=True):
    """
    æ ¹æ®ç”¨æˆ·è¾“å…¥é€‰æ‹©ä½¿ç”¨çš„è®¾å¤‡ï¼ˆCPUæˆ–GPUï¼‰ã€‚
    :param device: è®¾å¤‡åç§°
    :param batch_size: æ‰¹å¤„ç†å¤§å°
    :param newline: æ˜¯å¦æ¢è¡Œ
    :return: torch.deviceå®ä¾‹
    """
    s = f'YOLOv5 ğŸš€ {torch.__version__} '
    device = str(device).strip().lower().replace('cuda:', '').replace('none', '')
    cpu = device == 'cpu'
    if cpu:
        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
    elif device:
        os.environ['CUDA_VISIBLE_DEVICES'] = device
        assert torch.cuda.is_available() and torch.cuda.device_count() >= len(device.replace(',', '')), \
            f"Invalid CUDA '--device {device}' requested, use '--device cpu' or pass valid CUDA device(s)"

    if not cpu and torch.cuda.is_available():
        devices = device.split(',') if device else '0'
        n = len(devices)
        if n > 1 and batch_size > 0:
            assert batch_size % n == 0, f'batch-size {batch_size} not multiple of GPU count {n}'
        space = ' ' * (len(s) + 1)
        for i, d in enumerate(devices):
            p = torch.cuda.get_device_properties(i)
            s += f"{'' if i == 0 else space}CUDA:{d} ({p.name}, {p.total_memory / (1 << 20):.0f}MiB)\n"
        arg = 'cuda:0'
    else:
        s += 'CPU\n'
        arg = 'cpu'

    if not newline:
        s = s.rstrip()
    print(s)
    return torch.device(arg)

#3. è·å–è§†é¢‘æº
def get_video_info(input_video):
    """
    ä½¿ç”¨`ffprobe`è·å–è¾“å…¥è§†é¢‘çš„ç›¸å…³ä¿¡æ¯ï¼ˆå®½åº¦ã€é«˜åº¦ã€å¸§ç‡ï¼‰ã€‚
    :param input_video: è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„
    :return: è§†é¢‘å®½åº¦ã€é«˜åº¦å’Œå¸§ç‡
    """
    ffprobe_cmd = ['ffprobe', '-v', 'error', '-select_streams', 'v:0',
                   '-show_entries', 'stream=width,height,r_frame_rate',
                   '-of', 'csv=p=0', input_video]
    info = sp.check_output(ffprobe_cmd).decode('utf-8').split(',')
    width, height = map(int, info[:2])
    fps = round(eval(info[2]))
    return width, height, fps

# 4. é¢„å¤„ç†è§†é¢‘å¸§
def preprocess_frame(frame, height, crop_ratio=1, crop_top_ratio=0):
    """
    å¯¹è¾“å…¥çš„è§†é¢‘å¸§è¿›è¡Œè£å‰ªã€‚
    :param frame: è¾“å…¥çš„è§†é¢‘å¸§
    :param height: è§†é¢‘å¸§é«˜åº¦
    :param crop_ratio: è£å‰ªæ¯”ä¾‹
    :param crop_top_ratio: é¡¶éƒ¨è£å‰ªæ¯”ä¾‹
    :return: è£å‰ªåçš„è§†é¢‘å¸§
    """
    height_crop = int(height * crop_ratio)
    crop_top = int(height * crop_top_ratio)
    frame = frame[crop_top:crop_top + height_crop, :, :]
    return frame

# 5. è¿è¡Œç›®æ ‡æ£€æµ‹
def process_frame(frame, model):
    """
    ä½¿ç”¨YOLOv5æ¨¡å‹å¯¹è¾“å…¥çš„è§†é¢‘å¸§è¿›è¡Œç›®æ ‡æ£€æµ‹ã€‚
    :param frame: è¾“å…¥çš„è§†é¢‘å¸§
    :param model: YOLOv5æ¨¡å‹å®ä¾‹
    :return: ç»˜åˆ¶è¾¹ç•Œæ¡†åçš„è§†é¢‘å¸§
    """
    results = model.predict(frame)
    return draw_bboxes(frame, results)

# 7. åå¤„ç†
def draw_bboxes(img, results):
    """
    åœ¨è¾“å…¥çš„å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹åˆ°çš„è¾¹ç•Œæ¡†ã€‚
    :param img: è¾“å…¥çš„å›¾åƒ
    :param results: æ£€æµ‹ç»“æœ
    :return: ç»˜åˆ¶è¾¹ç•Œæ¡†åçš„å›¾åƒ
    """
    for *box, conf, cls in results.xyxy[0]:
        if int(cls) in [0, 1]:  # åªç»˜åˆ¶äººå’Œè½¦ä¸¤ä¸ªç±»åˆ«çš„æ£€æµ‹ç»“æœ
            label = f"{results.names[int(cls)]} {conf:.2f}"
            x1, y1, x2, y2 = map(int, box)
            img = cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)
            img = cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
    return img

# ä¸»ç¨‹åºæµç¨‹
if __name__ == '__main__':
    # 1.è·å–è§†é¢‘æºä¿¡æ¯
    input_video = 'C:/1602646269313.mp4'
    width, height, fps = get_video_info(input_video)

    # 2.è®¾ç½®æ¨¡æ‹Ÿè®¾å¤‡
    device = select_device(0)

    # 3.åŠ è½½æ¨¡å‹
    model_path = 'F:/12-Python/yolov5/pre_modelsfile_yolov5/yolov5s.pt'
    model = load_model(model_path, device)

    # 4.è®¾ç½®FFmpegå‘½ä»¤
    """
    ä»è¾“å…¥çš„è§†é¢‘æ–‡ä»¶ä¸­è¯»å–åŸå§‹è§†é¢‘å¸§æ•°æ®
    è®¾ç½®FFmpegå‘½ä»¤çš„ç›®çš„æ˜¯ä¸ºäº†æ„å»ºä¸€ä¸ªå‘½ä»¤è¡Œå‘½ä»¤ï¼Œè¿™ä¸ªå‘½ä»¤ç”¨äºå¯åŠ¨ä¸€ä¸ªå­è¿›ç¨‹ï¼ˆpipeï¼‰ã€‚
    å­è¿›ç¨‹çš„ä½œç”¨æ˜¯åœ¨åå°è¿è¡ŒFFmpegï¼Œä»¥ä¾¿å®æ—¶ä»è¾“å…¥çš„è§†é¢‘æ–‡ä»¶ä¸­è¯»å–å¹¶å¤„ç†åŸå§‹è§†é¢‘å¸§æ•°æ®ã€‚
    """
    command = ['ffmpeg',
               '-i', input_video,
                # '-vf', 'scale={}:{}'.format(new_width, new_height), # è®¾ç½®ç¼©æ”¾åçš„å®½åº¦å’Œé«˜åº¦
               '-vf', 'scale={}:{}'.format(width, height),
               '-c:v', 'rawvideo',
               '-pix_fmt', 'bgr24',
               '-threads', '6',
               '-f', 'rawvideo',
               'pipe:']

    # 5.pipeå­è¿›ç¨‹çš„ä½œç”¨æ˜¯åœ¨åå°è¿è¡ŒFFmpegï¼Œä»¥ä¾¿å®æ—¶ä»è¾“å…¥çš„è§†é¢‘æ–‡ä»¶ä¸­è¯»å–å¹¶å¤„ç†åŸå§‹è§†é¢‘å¸§æ•°æ®
    pipe = sp.Popen(command, stdout=sp.PIPE, bufsize=10**8)

    """
    6.cap:
    åˆ›å»ºä¸€ä¸ªVideoCaptureå¯¹è±¡capï¼Œå¹¶ä»¥input_videoä¸ºå‚æ•°ï¼Œå³è¾“å…¥è§†é¢‘æ–‡ä»¶çš„è·¯å¾„ã€‚
    VideoCaptureå¯¹è±¡å¯ä»¥ä»è¾“å…¥è§†é¢‘ä¸­è¯»å–å¸§æ•°æ®ï¼Œè¿™å¯¹äºå®æ—¶å¤„ç†è§†é¢‘å¸§éå¸¸æœ‰ç”¨ã€‚
    """
    cap = cv2.VideoCapture(input_video)

    """
    buffer_size
    ç”¨äºè®¾ç½®VideoCaptureå¯¹è±¡çš„å†…éƒ¨ç¼“å†²åŒºå¤§å°ã€‚
    è¾ƒå¤§çš„ç¼“å†²åŒºå¤§å°å¯ä»¥å‡å°‘ä»è§†é¢‘æ–‡ä»¶ä¸­è¯»å–å¸§æ•°æ®çš„å»¶è¿Ÿï¼Œä»è€Œæé«˜è§†é¢‘å¤„ç†çš„æ•ˆç‡ã€‚
    """
    buffer_size = 30

    """
    7.cap.set()æ–¹æ³•:
    è®¾ç½®VideoCaptureå¯¹è±¡çš„ç¼“å†²åŒºå¤§å°ã€‚é€šè¿‡è°ƒç”¨cap.set()æ–¹æ³•å¹¶ä¼ å…¥ä¸¤ä¸ªå‚æ•°ï¼š
    cv2.CAP_PROP_BUFFERSIZEï¼ˆè¡¨ç¤ºè¦è®¾ç½®çš„å±æ€§æ˜¯ç¼“å†²åŒºå¤§å°ï¼‰
    buffer_sizeï¼ˆè¦è®¾ç½®çš„ç¼“å†²åŒºå¤§å°å€¼ï¼‰ã€‚
    """
    cap.set(cv2.CAP_PROP_BUFFERSIZE, buffer_size)


    """
    8.executor
    åˆ›å»ºä¸€ä¸ªçº¿ç¨‹æ± ï¼Œæœ€å¤§çº¿ç¨‹æ•°ä¸º6ã€‚çº¿ç¨‹æ± ç”¨äºå¹¶å‘åœ°æ‰§è¡Œå¤šä¸ªä»»åŠ¡ï¼Œè¿™é‡Œç”¨äºå¹¶å‘å¤„ç†è§†é¢‘å¸§çš„ç›®æ ‡æ£€æµ‹ä»»åŠ¡ã€‚
    """
    executor = ThreadPoolExecutor(max_workers=10)

    """
    9.skip_frames
    è®¾ç½®è·³è¿‡çš„å¸§æ•°ã€‚å¦‚æœå¸Œæœ›å¤„ç†è¾“å…¥è§†é¢‘çš„æ¯ä¸€å¸§ï¼Œåˆ™å°†æ­¤å€¼è®¾ç½®ä¸º1ã€‚
    å¦‚æœå¸Œæœ›è·³è¿‡éƒ¨åˆ†å¸§ï¼Œå¯ä»¥å°†æ­¤å€¼å¢å¤§ã€‚è¿™æ ·å¯ä»¥å‡å°‘å¤„ç†çš„å¸§æ•°ï¼Œæé«˜å¤„ç†é€Ÿåº¦ï¼Œä½†å¯èƒ½ä¼šå¯¼è‡´æ£€æµ‹ç»“æœä¸é‚£ä¹ˆå‡†ç¡®ã€‚
    """
    skip_frames = 1

    """
    åˆå§‹åŒ–å¸§è®¡æ•°å™¨
    """
    frame_counter = 0

    """
    10.frame_futures = [] çš„ä½œç”¨æ˜¯åˆ›å»ºä¸€ä¸ªç©ºåˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨å¤„ç†è§†é¢‘å¸§ä»»åŠ¡çš„futureå¯¹è±¡ã€‚
    futureå¯¹è±¡ä»£è¡¨ç€ä¸€ä¸ªå°šæœªå®Œæˆçš„è®¡ç®—ä»»åŠ¡ï¼Œå½“ä»»åŠ¡å®Œæˆåï¼Œå¯ä»¥é€šè¿‡future.result()è·å–ä»»åŠ¡çš„ç»“æœã€‚

    å°†frame_futures = []æ”¾åœ¨è¿™ä¸ªä½ç½®çš„åŸå› æ˜¯ï¼Œåœ¨å¼€å§‹å¤„ç†è§†é¢‘å¸§çš„å¾ªç¯ä¹‹å‰ï¼Œéœ€è¦åˆå§‹åŒ–è¿™ä¸ªåˆ—è¡¨ã€‚
    åœ¨åç»­çš„å¾ªç¯ä¸­ï¼Œæ¯å¤„ç†ä¸€ä¸ªè§†é¢‘å¸§ï¼Œéƒ½ä¼šå°†è¯¥å¸§å¯¹åº”çš„futureå¯¹è±¡æ·»åŠ åˆ°frame_futuresåˆ—è¡¨ä¸­ã€‚
    å½“åˆ—è¡¨ä¸­çš„futureå¯¹è±¡æ•°é‡è¶…è¿‡ç¼“å†²åŒºå¤§å°ï¼ˆbuffer_sizeï¼‰æ—¶ï¼Œä¾¿ä»åˆ—è¡¨ä¸­å–å‡ºç¬¬ä¸€ä¸ªfutureå¯¹è±¡ï¼Œ
    ç­‰å¾…ä»»åŠ¡å®Œæˆï¼Œå¹¶è·å–å¤„ç†ç»“æœã€‚è¿™ç§æ–¹å¼å¯ä»¥å®ç°å¹¶å‘å¤„ç†å¤šä¸ªè§†é¢‘å¸§ï¼Œæé«˜ç¨‹åºçš„æ‰§è¡Œæ•ˆç‡ã€‚
    """
    frame_futures = []

    processed_frame_counter = 0

    while True:
        ret, frame = cap.read()

        if not ret:
            break

        if not ret or frame_counter % skip_frames != 0:
            frame_counter += 1 # æ˜¯ç”¨äºè·³è¿‡ä¸€äº›å¸§ä»¥åŠ é€Ÿå¤„ç†ã€‚å½“æ£€æµ‹åˆ°è¯¥å¸§ä¸æ˜¯è¦å¤„ç†çš„å¸§æ—¶ï¼Œå°±ç›´æ¥è·³è¿‡ï¼Œä¸è¿›è¡Œå¤„ç†ã€‚
            continue

         # 11.é¦–å¸§æ˜¾ç¤ºæ—¶è®°å½•æ—¶é—´
        if frame_counter == 1:
            start_timeProcessed = time.time()

        frame = preprocess_frame(frame, height)

        frame_counter += 1

        if frame_counter % 10 == 0:
            end_time = time.time()
            elapsed_Processedtime = end_time - start_timeProcessed
            print(f"Processed frames: {frame_counter}, Processed time_: {elapsed_Processedtime:.2f}s")

        future = executor.submit(process_frame, frame, model)
        frame_futures.append(future)

        # 12.å½“æœ‰è¶³å¤Ÿçš„å¸§ç¼“å†²æ—¶ï¼Œæ”¶é›†ç¬¬ä¸€ä¸ªä»»åŠ¡çš„ç»“æœ
        if len(frame_futures) > buffer_size:
            processed_frame = frame_futures.pop(0).result()
            processed_frame_counter += 1

            # 13.é¦–å¸§æ˜¾ç¤ºæ—¶è®°å½•æ—¶é—´
            if processed_frame_counter == 1:
                start_time = time.time()

            current_time = time.time()
            elapsed_time = current_time - start_time

            #14.æ˜¾ç¤ºçº¿ç¨‹æ•°é‡
            active_threads = threading.active_count()
            print(f"Active threads: {active_threads}")

            # 15.åœ¨å±å¹•ä¸Šå®æ—¶æ˜¾ç¤ºå·²ç»å¤„ç†çš„å¸§æ•°å’ŒèŠ±è´¹çš„æ—¶é—´
            cv2.putText(frame, f"frame: {frame_counter}", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255),
                        2)
            cv2.putText(frame, f"video.time: {elapsed_time:.2f}s", (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 1,
                        (0, 0, 255), 2)

            # 16.æ˜¾ç¤ºå¤„ç†åçš„å¸§
            cv2.imshow('Video', processed_frame)

            # time.sleep(1 / fps)

            if cv2.waitKey(int(1000/fps)) & 0xFF == ord('q'):
                break

            pipe.stdout.flush()

        # æœ€åä¸€å¸§æ˜¾ç¤ºæ—¶è®¡ç®—ç»è¿‡çš„æ—¶é—´
        if frame_counter == 470:
            end_time = time.time()
            elapsed_time = end_time - start_time
            print(f"Elapsed time by frame_counter 470: {elapsed_time:.2f}s")
            break



    # é‡Šæ”¾èµ„æº
    # out.release()
    cap.release()

    cv2.destroyAllWindows()

    pipe.stdout.flush()

    pipe.communicate()


