import torch
from yolov5 import YOLOv5
import os
import sys
import cv2
from PyQt6.QtWidgets import QApplication, QMainWindow, QLabel, QVBoxLayout, QWidget
from PyQt6.QtGui import QImage, QPixmap
from PyQt6.QtCore import QTimer


#1. åŠ è½½æ¨¡åž‹
def load_model(model_path, device):
    """
    åŠ è½½é¢„è®­ç»ƒçš„YOLOv5æ¨¡åž‹ã€‚
    :param model_path: æ¨¡åž‹æ–‡ä»¶è·¯å¾„
    :param device: è®¡ç®—è®¾å¤‡ï¼ˆCPUæˆ–GPUï¼‰
    :return: åŠ è½½çš„æ¨¡åž‹å®žä¾‹
    """
    return YOLOv5(model_path, device=device)

#2. è®¾ç½®GPU
def select_device(device='', batch_size=0, newline=True):
    """
    æ ¹æ®ç”¨æˆ·è¾“å…¥é€‰æ‹©ä½¿ç”¨çš„è®¾å¤‡ï¼ˆCPUæˆ–GPUï¼‰ã€‚
    :param device: è®¾å¤‡åç§°
    :param batch_size: æ‰¹å¤„ç†å¤§å°
    :param newline: æ˜¯å¦æ¢è¡Œ
    :return: torch.deviceå®žä¾‹
    """
    s = f'YOLOv5 ðŸš€ {torch.__version__} '
    device = str(device).strip().lower().replace('cuda:', '').replace('none', '')
    cpu = device == 'cpu'
    if cpu:
        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
    elif device:
        os.environ['CUDA_VISIBLE_DEVICES'] = device
        assert torch.cuda.is_available() and torch.cuda.device_count() >= len(device.replace(',', '')), \
            f"Invalid CUDA '--device {device}' requested, use '--device cpu' or pass valid CUDA device(s)"

    if not cpu and torch.cuda.is_available():
        devices = device.split(',') if device else '0'
        n = len(devices)
        if n > 1 and batch_size > 0:
            assert batch_size % n == 0, f'batch-size {batch_size} not multiple of GPU count {n}'
        space = ' ' * (len(s) + 1)
        for i, d in enumerate(devices):
            p = torch.cuda.get_device_properties(i)
            s += f"{'' if i == 0 else space}CUDA:{d} ({p.name}, {p.total_memory / (1 << 20):.0f}MiB)\n"
        arg = 'cuda:0'
    else:
        s += 'CPU\n'
        arg = 'cpu'

    if not newline:
        s = s.rstrip()
    print(s)
    return torch.device(arg)

#3. èŽ·å–è§†é¢‘æº
def get_video_info(input_video):
    """
    ä½¿ç”¨OpenCVèŽ·å–è¾“å…¥è§†é¢‘çš„ç›¸å…³ä¿¡æ¯ï¼ˆå®½åº¦ã€é«˜åº¦ã€å¸§çŽ‡ï¼‰ã€‚
    :param input_video: è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„
    :return: è§†é¢‘å®½åº¦ã€é«˜åº¦å’Œå¸§çŽ‡
    """
    cap = cv2.VideoCapture(input_video)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    cap.release()
    return width, height, fps

# 4. é¢„å¤„ç†è§†é¢‘å¸§
def preprocess_frame(frame, height, crop_ratio=0.7, crop_top_ratio=0.15):
    """
    å¯¹è¾“å…¥çš„è§†é¢‘å¸§è¿›è¡Œè£å‰ªã€‚
    :param frame: è¾“å…¥çš„è§†é¢‘å¸§
    :param height: è§†é¢‘å¸§é«˜åº¦
    :param crop_ratio: è£å‰ªæ¯”ä¾‹
    :param crop_top_ratio: é¡¶éƒ¨è£å‰ªæ¯”ä¾‹
    :return: è£å‰ªåŽçš„è§†é¢‘å¸§
    """
    height_crop = int(height * crop_ratio)
    crop_top = int(height * crop_top_ratio)
    frame = frame[crop_top:crop_top + height_crop, :, :]
    return frame

# 5. è¿è¡Œç›®æ ‡æ£€æµ‹
def process_frame(frame, model):
    """
    ä½¿ç”¨YOLOv5æ¨¡åž‹å¯¹è¾“å…¥çš„è§†é¢‘å¸§è¿›è¡Œç›®æ ‡æ£€æµ‹ã€‚
    :param frame: è¾“å…¥çš„è§†é¢‘å¸§
    :param model: YOLOv5æ¨¡åž‹å®žä¾‹
    :return: ç»˜åˆ¶è¾¹ç•Œæ¡†åŽçš„è§†é¢‘å¸§
    """
    results = model.predict(frame)
    return draw_bboxes(frame, results)

# 7. åŽå¤„ç†
def draw_bboxes(img, results):
    """
    åœ¨è¾“å…¥çš„å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹åˆ°çš„è¾¹ç•Œæ¡†ã€‚
    :param img: è¾“å…¥çš„å›¾åƒ
    :param results: æ£€æµ‹ç»“æžœ
    :return: ç»˜åˆ¶è¾¹ç•Œæ¡†åŽçš„å›¾åƒ
    """
    for *box, conf, cls in results.xyxy[0]:
        if int(cls) in [0, 1]:  # åªç»˜åˆ¶äººå’Œè½¦ä¸¤ä¸ªç±»åˆ«çš„æ£€æµ‹ç»“æžœ
            label = f"{results.names[int(cls)]} {conf:.2f}"
            x1, y1, x2, y2 = map(int, box)
            img = cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)
            img = cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
    return img

# ä¸»ç¨‹åºæµç¨‹
# çœç•¥å‰é¢çš„ä»£ç 
class MainWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        input_video = 0
        device = select_device(0)
        model_path = 'F:/12-Python/yolov5/pre_modelsfile_yolov5/yolov5s.pt'
        model = load_model(model_path, device)
        self.model = model
        self.cap = cv2.VideoCapture(input_video)

        self.init_ui()

        self.timer = QTimer()
        self.timer.timeout.connect(self.update_frame)
        self.timer.start(1000 // 30)  # è®¾ç½®åˆ·æ–°çŽ‡ï¼Œä¾‹å¦‚ 30 FPS

    def init_ui(self):
        self.setWindowTitle('YOLOv5 Detection')
        self.setGeometry(100, 100, 800, 600)

        layout = QVBoxLayout()

        self.label = QLabel(self)
        layout.addWidget(self.label)

        container = QWidget()
        container.setLayout(layout)
        self.setCentralWidget(container)

    def update_frame(self):
        ret, frame = self.cap.read()

        if not ret:
            return

        # å¯¹å¸§è¿›è¡Œå¤„ç†ï¼Œä¾‹å¦‚æ£€æµ‹
        height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        frame = preprocess_frame(frame, height)
        frame = process_frame(frame, self.model)

        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        h, w, ch = frame.shape
        bytes_per_line = ch * w

        image = QImage(frame.data, w, h, bytes_per_line, QImage.Format.Format_RGB888)
        self.label.setPixmap(QPixmap.fromImage(image))

    def closeEvent(self, event):
        self.timer.stop()
        self.cap.release()

if __name__ == '__main__':
    app = QApplication(sys.argv)


    window = MainWindow()
    window.show()

    sys.exit(app.exec())