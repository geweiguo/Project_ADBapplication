import torch
from yolov5 import YOLOv5
import os
import cv2

#1. åŠ è½½æ¨¡åž‹
def load_model(model_path, device):
    """
    åŠ è½½é¢„è®­ç»ƒçš„YOLOv5æ¨¡åž‹ã€‚
    :param model_path: æ¨¡åž‹æ–‡ä»¶è·¯å¾„
    :param device: è®¡ç®—è®¾å¤‡ï¼ˆCPUæˆ–GPUï¼‰
    :return: åŠ è½½çš„æ¨¡åž‹å®žä¾‹
    """
    return YOLOv5(model_path, device=device)

#2. è®¾ç½®GPU


def select_device(device='', batch_size=0, newline=True):
    """
    æ ¹æ®ç”¨æˆ·è¾“å…¥é€‰æ‹©ä½¿ç”¨çš„è®¾å¤‡ï¼ˆCPUæˆ–GPUï¼‰ã€‚
    :param device: è®¾å¤‡åç§°
    :param batch_size: æ‰¹å¤„ç†å¤§å°
    :param newline: æ˜¯å¦æ¢è¡Œ
    :return: torch.deviceå®žä¾‹
    """
    s = f'YOLOv5 ðŸš€ {torch.__version__} '
    device = str(device).strip().lower().replace('cuda:', '').replace('none', '')
    cpu = device == 'cpu'
    if cpu:
        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
    elif device:
        os.environ['CUDA_VISIBLE_DEVICES'] = device
        assert torch.cuda.is_available() and torch.cuda.device_count() >= len(device.replace(',', '')), \
            f"Invalid CUDA '--device {device}' requested, use '--device cpu' or pass valid CUDA device(s)"

    if not cpu and torch.cuda.is_available():
        devices = device.split(',') if device else '0'
        n = len(devices)
        if n > 1 and batch_size > 0:
            assert batch_size % n == 0, f'batch-size {batch_size} not multiple of GPU count {n}'
        space = ' ' * (len(s) + 1)
        for i, d in enumerate(devices):
            p = torch.cuda.get_device_properties(i)
            s += f"{'' if i == 0 else space}CUDA:{d} ({p.name}, {p.total_memory / (1 << 20):.0f}MiB)\n"
        arg = 'cuda:0'
    else:
        s += 'CPU\n'
        arg = 'cpu'

    if not newline:
        s = s.rstrip()
    print(s)
    print(f"Selected device: {arg}")  # æ·»åŠ è°ƒè¯•è¾“å‡º
    return torch.device(arg)

#3. èŽ·å–è§†é¢‘æº
def get_video_info(input_video):
    """
    ä½¿ç”¨OpenCVèŽ·å–è¾“å…¥è§†é¢‘çš„ç›¸å…³ä¿¡æ¯ï¼ˆå®½åº¦ã€é«˜åº¦ã€å¸§çŽ‡ï¼‰ã€‚
    :param input_video: è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„
    :return: è§†é¢‘å®½åº¦ã€é«˜åº¦å’Œå¸§çŽ‡
    """
    cap = cv2.VideoCapture(input_video)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    cap.release()
    return width, height, fps

# 4. é¢„å¤„ç†è§†é¢‘å¸§
def preprocess_frame(frame, height, settings):

    """
    å¯¹è¾“å…¥çš„è§†é¢‘å¸§è¿›è¡Œè£å‰ªã€‚
    :param frame: è¾“å…¥çš„è§†é¢‘å¸§
    :param height: è§†é¢‘å¸§é«˜åº¦
    :param crop_ratio: è£å‰ªæ¯”ä¾‹
    :param crop_top_ratio: é¡¶éƒ¨è£å‰ªæ¯”ä¾‹
    :return: è£å‰ªåŽçš„è§†é¢‘å¸§
    """
    crop_ratio = settings.crop_ratio
    crop_top_ratio = settings.crop_top_ratio
    scale_ratio = settings.scale_ratio

    height_crop = int(height * crop_ratio)
    crop_top = int(height * crop_top_ratio)
    frame = frame[crop_top:crop_top + height_crop, :, :]

    # ç¼©æ”¾æ“ä½œ
    new_width = int(frame.shape[1] * scale_ratio)
    new_height = int(frame.shape[0] * scale_ratio)
    frame = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_AREA)

    return frame

# 5. è¿è¡Œç›®æ ‡æ£€æµ‹
def process_frame(frame, model):
    """
    ä½¿ç”¨YOLOv5æ¨¡åž‹å¯¹è¾“å…¥çš„è§†é¢‘å¸§è¿›è¡Œç›®æ ‡æ£€æµ‹ã€‚
    :param frame: è¾“å…¥çš„è§†é¢‘å¸§
    :param model: YOLOv5æ¨¡åž‹å®žä¾‹
    :return: ç»˜åˆ¶è¾¹ç•Œæ¡†åŽçš„è§†é¢‘å¸§
    """
    results = model.predict(frame)
    return draw_bboxes(frame, results)

# 6. åŽå¤„ç†
def draw_bboxes(img, results):
    """
    åœ¨è¾“å…¥çš„å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹åˆ°çš„è¾¹ç•Œæ¡†ã€‚
    :param img: è¾“å…¥çš„å›¾åƒ
    :param results: æ£€æµ‹ç»“æžœ
    :return: ç»˜åˆ¶è¾¹ç•Œæ¡†åŽçš„å›¾åƒ
    """
    for *box, conf, cls in results.xyxy[0]:
        if int(cls) in [0, 1]:  # åªç»˜åˆ¶äººå’Œè½¦ä¸¤ä¸ªç±»åˆ«çš„æ£€æµ‹ç»“æžœ
            label = f"{results.names[int(cls)]} {conf:.2f}"
            x1, y1, x2, y2 = map(int, box)
            img = cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)
            img = cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
    return img
